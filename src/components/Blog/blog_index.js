const BlogIndex = [
  {
    slug: 'machine-learning-overview',
    title: 'Machine Learning: A High-Level Overview',
    preview: `A brief orientation for complete novices in the field of machine learning to gain a better understanding
              on the fundamentals of what machine learning is, how it is used, and the general framework for how it works.`,
    date: 'July 19th, 2025',
    readTime: '5 min read',
    category: 'Data Science',
  },
  {
    slug: 'math-review',
    title: 'The Math Behind Machine Learning',
    preview: `If terms like gradients, dot products, or partial derivatives feel a little rusty, this post walks through the key 
              math concepts behind machine learning: linear algebra, calculus, and probability without diving too deep.`,
    date: 'July 19th, 2025',
    readTime: '10 min read',
    category: 'Data Science',
  },
  {
    slug: 'linear-regression',
    title:
      "How Linear Regression Works (and Why it's the Foundation of Machine Learning)",
    preview: `In this post, I'll break down what linear regression is, how it makes predictions, and how it learns from data. 
              You'll see how this one model introduces key ideas like feature vectors, model parameters, loss functions, and gradient 
              descent.`,
    date: 'July 21st, 2025',
    readTime: '15 min read',
    category: 'Data Science',
  },
  {
    slug: 'linear-perceptron',
    title:
      'From Lines to Layers: The Linear Perceptron and the Rise of Neural Networks',
    preview: `At the heart of today's neural networks lies a surprisingly simple ideaâ€”the perceptron.
              This post unpacks how this classic algorithm works, how it learns to seperate data, and how
              stacking these simple units leads to powerful models that drive today's AI.`,
    date: 'July 30th, 2025',
    readTime: '12 min read',
    category: 'Data Science',
  },
  {
    slug: 'logistic-regression',
    title: 'Logistic Regression: Turning Probabilities into Predictions',
    preview: `Beneath the math, logistic regression is a clever way to draw a straight line between two classes.
              This post breaks down how we turn its inputs into probabilities and predictions, how it dffers from the linear perceptron,
              and how it powers real-world decisions like sports preditions.`,
    date: 'August 7th, 2025',
    readTime: '20 min read',
    category: 'Data Science',
  },
  {
    slug: 'svm',
    title: 'Margins, Kernels, and Support Vectors: An Intuitive Guide to SVMs',
    preview: `What makes a good decision boundary? Points that lie far away from the boundary can be classified with confidence, while those close to it sit in a gray area. SVMs aim to maximize this distance from the decision boundary. With the help of 
              kernels, they can even reshape the coordinate space to make accurate predictions with complex data.`,
    date: 'August 25th, 2025',
    readTime: '25 min read',
    category: 'Data Science',
  },
]

export default BlogIndex
